{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fae5c1cc",
      "metadata": {
        "id": "fae5c1cc"
      },
      "source": [
        "# Business Problem Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bc9f2a",
      "metadata": {
        "id": "f4bc9f2a"
      },
      "source": [
        "## FreshMart: Maximising Total Sales Revenue through Smarter Retail Decisions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dada6131",
      "metadata": {
        "id": "dada6131"
      },
      "source": [
        "FreshMart is a fast-growing grocery retail chain based in the United States, serving thousands of customers across various cities and countries. Known for its wide product range and affordable pricing, FreshMart has built a strong presence in both urban and suburban markets.\n",
        "\n",
        "As the company prepares for its next phase of growth, leadership wants to focus not just on adding new stores, but on increasing Total Sales Revenue from its existing network. This means a better understanding what drives revenue, from which products perform well, to how different regions, customer segments, and sales staff contribute to the bottom line.\n",
        "\n",
        "The company believes there are many untapped opportunities to grow sales. These may lie in:\n",
        "\n",
        "- how product categories perform across months,\n",
        "- which types of customers spend more,\n",
        "- how employees contribute to store-level sales,\n",
        "- which cities or countries have higher or lower sales, and\n",
        "- how discounts are influencing buying behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d124780",
      "metadata": {
        "id": "0d124780"
      },
      "source": [
        "### Key Metric: Total Sales Revenue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "292e7f69",
      "metadata": {
        "id": "292e7f69"
      },
      "source": [
        "$\\text{Total Sales Revenue} = \\text{Unit Price} \\times \\text{Quantity} \\times (1 - \\text{Discount})$. This metric helps measure how much money FreshMart is making from selling products after applying discounts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e058e4",
      "metadata": {
        "id": "f1e058e4"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f090ff06",
      "metadata": {
        "id": "f090ff06"
      },
      "source": [
        "The objective of this project is to:\n",
        "\n",
        "- Break down Total Sales Revenue into its core components such as product price, quantity sold, and discounts applied.\n",
        "- Explore how different product categories, classifications, and features contribute to revenue across time.\n",
        "- Segment customers based on order value, quantity purchased, and spending behavior.\n",
        "- Evaluate the performance of individual sales employees and understand how their contribution varies by region or time.\n",
        "- Compare city-wise and country-wise sales patterns to highlight high- and low-performing areas.\n",
        "- Analyse trends over time to understand when sales peak or drop, and how this differs by product or location."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2829805b",
      "metadata": {
        "id": "2829805b"
      },
      "source": [
        "# Dataset Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c48a995",
      "metadata": {
        "id": "6c48a995"
      },
      "source": [
        "- **Dataset Name:** FreshMart Analytics Dataset\n",
        "- **Number of Tables:** 7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "245ecbcc",
      "metadata": {
        "id": "245ecbcc"
      },
      "source": [
        "## Table Overviews"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67299299",
      "metadata": {
        "id": "67299299"
      },
      "source": [
        "### categories"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec64311d",
      "metadata": {
        "id": "ec64311d"
      },
      "source": [
        "- **Table Name:** categories\n",
        "- **Number of rows:** 11\n",
        "- **Number of columns:** 2\n",
        "- **Description:** This table gives the different product categories that FreshMart sells."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8e7cdd",
      "metadata": {
        "id": "be8e7cdd"
      },
      "source": [
        "### cities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3e46ba",
      "metadata": {
        "id": "7d3e46ba"
      },
      "source": [
        "- **Table Name:** cities\n",
        "- **Number of rows:** 96\n",
        "- **Number of columns:** 4\n",
        "- **Description:** This table gives a list of cities and zipcodes FreshMart operates in."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00c7d7a",
      "metadata": {
        "id": "c00c7d7a"
      },
      "source": [
        "### countries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74583f8f",
      "metadata": {
        "id": "74583f8f"
      },
      "source": [
        "- **Table Name:** countries\n",
        "- **Number of rows:** 206\n",
        "- **Number of columns:** 3\n",
        "- **Description:** This table gives a list of countries FreshMart operates in."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "913da6ec",
      "metadata": {
        "id": "913da6ec"
      },
      "source": [
        "### customers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c46cce",
      "metadata": {
        "id": "c4c46cce"
      },
      "source": [
        "- **Table Name:** customers\n",
        "- **Number of rows:** 98759\n",
        "- **Number of columns:** 6\n",
        "- **Description:** This table gives details of FreshMart customers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a704790",
      "metadata": {
        "id": "8a704790"
      },
      "source": [
        "### employees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f83c85",
      "metadata": {
        "id": "e1f83c85"
      },
      "source": [
        "- **Table Name:** employees\n",
        "- **Number of rows:** 23\n",
        "- **Number of columns:** 8\n",
        "- **Description:** This table gives details of FreshMart employees."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92beffd2",
      "metadata": {
        "id": "92beffd2"
      },
      "source": [
        "### products"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25c8f4e",
      "metadata": {
        "id": "f25c8f4e"
      },
      "source": [
        "- **Table Name:** products\n",
        "- **Number of rows:** 452\n",
        "- **Number of columns:** 9\n",
        "- **Description:** This table gives details of the products sold by FreshMart."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd7363b",
      "metadata": {
        "id": "2cd7363b"
      },
      "source": [
        "### sales"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2312a31",
      "metadata": {
        "id": "f2312a31"
      },
      "source": [
        "- **Table Name:** sales\n",
        "- **Number of rows:** 6758125\n",
        "- **Number of columns:** 9\n",
        "- **Description:** This table gives detailed transaction history of FreshMart."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2bd019e",
      "metadata": {
        "id": "e2bd019e"
      },
      "source": [
        "## Column Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "681bdceb",
      "metadata": {
        "id": "681bdceb"
      },
      "source": [
        "### categories"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a77e3b",
      "metadata": {
        "id": "70a77e3b"
      },
      "source": [
        "* **CategoryID**\n",
        "    * Description: Unique identifier for each product category.\n",
        "    * Example: 1\n",
        "* **CategoryName**\n",
        "    * Description: Name of the product category.\n",
        "    * Example: Beverages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbeb5e0f",
      "metadata": {
        "id": "cbeb5e0f"
      },
      "source": [
        "### cities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a7e036c",
      "metadata": {
        "id": "5a7e036c"
      },
      "source": [
        "* **CityID**\n",
        "    * Description: Unique identifier for each city.\n",
        "    * Example: 101\n",
        "* **CityName**\n",
        "    * Description: Name of the city.\n",
        "    * Example: San Diego\n",
        "* **Zipcode**\n",
        "    * Description: Represents the zipcode the city is in.\n",
        "    * Example: 500000\n",
        "* **CountryID**\n",
        "    * Description: Reference to the corresponding country from countries.\n",
        "    * Example: 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e74c29",
      "metadata": {
        "id": "24e74c29"
      },
      "source": [
        "### countries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bc7ac79",
      "metadata": {
        "id": "2bc7ac79"
      },
      "source": [
        "  * **CountryID**\n",
        "    * Description: Unique identifier for each country.\n",
        "    * Example: 1\n",
        "  * **CountryName**\n",
        "    * Description: Name of the country.\n",
        "    * Example: United States\n",
        "  * **CountryCode**\n",
        "    * Description: Two-letter country code.\n",
        "    * Example: US\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6be68f",
      "metadata": {
        "id": "7c6be68f"
      },
      "source": [
        "### customers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27434801",
      "metadata": {
        "id": "27434801"
      },
      "source": [
        "  * **CustomerID**\n",
        "    * Description: Unique identifier for each customer.\n",
        "    * Example: 1001\n",
        "  * **FirstName**\n",
        "    * Description: First name of the customer.\n",
        "    * Example: Emma\n",
        "  * **MiddleInitial**\n",
        "    * Description: Middle initial of the customer.\n",
        "    * Example: A\n",
        "  * **LastName**\n",
        "    * Description: Last name of the customer.\n",
        "    * Example: Johnson\n",
        "  * **cityID**\n",
        "    * Description: City of the customer. Refers to cities.\n",
        "    * Example: 101\n",
        "  * **Address**\n",
        "    * Description: Residential address of the customer.\n",
        "    * Example: 123 Elm Street\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53fd526",
      "metadata": {
        "id": "b53fd526"
      },
      "source": [
        "### employees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e309ab",
      "metadata": {
        "id": "24e309ab"
      },
      "source": [
        "  * **EmployeeID**\n",
        "    * Description: Unique identifier for each employee.\n",
        "    * Example: 501\n",
        "  * **FirstName**\n",
        "    * Description: First name of the employee.\n",
        "    * Example: Michael\n",
        "  * **MiddleInitial**\n",
        "    * Description: Middle initial of the employee.\n",
        "    * Example: B\n",
        "  * **LastName**\n",
        "    * Description: Last name of the employee.\n",
        "    * Example: Davis\n",
        "  * **BirthDate**\n",
        "    * Description: Date of birth of the employee in YYYY-MM-DD format.\n",
        "    * Example: 1985-07-14\n",
        "  * **Gender**\n",
        "    * Description: Gender of the employee.\n",
        "    * Example: Male\n",
        "  * **CityID**\n",
        "    * Description: City where the employee is based. Refers to cities.\n",
        "    * Example: 103\n",
        "  * **HireDate**\n",
        "    * Description: Date when the employee was hired.\n",
        "    * Example: 2021-04-01\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0067e78f",
      "metadata": {
        "id": "0067e78f"
      },
      "source": [
        "### products"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4609b3a",
      "metadata": {
        "id": "a4609b3a"
      },
      "source": [
        "  * **ProductID**\n",
        "    * Description: Unique identifier for each product.\n",
        "    * Example: 301\n",
        "  * **ProductName**\n",
        "    * Description: Name of the product.\n",
        "    * Example: Organic Apple\n",
        "  * **Price**\n",
        "    * Description: Unit price of the product in USD.\n",
        "    * Example: 3.50\n",
        "  * **CategoryID**\n",
        "    * Description: Category reference for the product. Refers to categories.\n",
        "    * Example: 2\n",
        "  * **Class**\n",
        "    * Description: Classification type of the product (e.g., Standard, Premium).\n",
        "    * Example: Premium\n",
        "  * **ModifyDate**\n",
        "    * Description: Date when the product information was last updated.\n",
        "    * Example: 2023-06-01\n",
        "  * **Resistant**\n",
        "    * Description: Product resistance category.\n",
        "    * Example: Water-resistant\n",
        "  * **IsAllergic**\n",
        "    * Description: Indicates whether the item contains allergens.\n",
        "    * Example: No\n",
        "  * **VitalityDays**\n",
        "    * Description: Indicates the product's shelf life or freshness period.\n",
        "    * Example: 7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a82d7e77",
      "metadata": {
        "id": "a82d7e77"
      },
      "source": [
        "### sales"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1919bea7",
      "metadata": {
        "id": "1919bea7"
      },
      "source": [
        "  * **SalesID**\n",
        "    * Description: Unique identifier for each sale.\n",
        "    * Example: 7001\n",
        "  * **SalesPersonID**\n",
        "    * Description: Employee responsible for the sale. Refers to employees.\n",
        "    * Example: 501\n",
        "  * **CustomerID**\n",
        "    * Description: Customer making the purchase. Refers to customers.\n",
        "    * Example: 1001\n",
        "  * **ProductID**\n",
        "    * Description: Product being sold. Refers to products.\n",
        "    * Example: 301\n",
        "  * **Quantity**\n",
        "    * Description: Number of product units sold.\n",
        "    * Example: 3\n",
        "  * **Discount**\n",
        "    * Description: Discount applied to this sale, shown as a decimal.\n",
        "    * Example: 0.10\n",
        "  * **TotalPrice**\n",
        "    * Description: Final sale price after applying discount.\n",
        "    * Example: 9.45\n",
        "  * **SalesDate**\n",
        "    * Description: Date and time of the sale in YYYY-MM-DD HH:MM:SS format.\n",
        "    * Example: 2024-05-15 14:32:00\n",
        "  * **TransactionNumber**\n",
        "    * Description: Unique identifier for the transaction.\n",
        "    * Example: TXN-20240515-0001\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e0db31",
      "metadata": {
        "id": "05e0db31"
      },
      "source": [
        "## Relationships Between the Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63d495da",
      "metadata": {
        "id": "63d495da"
      },
      "source": [
        "|Table 1| Key Column(s) | Table 2| Key Column(s)|\n",
        "|-------|--------------|---------|---------------|\n",
        "|sales|CustomerID|customers|CustomerID|\n",
        "|sales|ProductID|products|ProductID|\n",
        "|sales|SalesPersonID|employees|EmployeeID|\n",
        "|employees|CityID|cities|CityID|\n",
        "|customers|CityID|cities|CityID|\n",
        "|cities|CountryID|countries|CountryID|\n",
        "|products|CategoryID|categories|CategoryID|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a796cb",
      "metadata": {
        "id": "b0a796cb"
      },
      "source": [
        "# Analysis & Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab1cb696",
      "metadata": {
        "id": "ab1cb696"
      },
      "source": [
        "## 1. Importing and Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2373a402",
      "metadata": {
        "id": "2373a402"
      },
      "source": [
        "### Importing the Necessary Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e940fa94",
      "metadata": {
        "id": "e940fa94"
      },
      "source": [
        "#### Install the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536745f0",
      "metadata": {
        "id": "536745f0"
      },
      "outputs": [],
      "source": [
        "# To download files from Google Drive\n",
        "%pip install gdown\n",
        "\n",
        "# To get output in markdown format\n",
        "%pip install ipython\n",
        "\n",
        "# To work with dataframes\n",
        "%pip install pandas\n",
        "\n",
        "# To display dataframes in markdown text\n",
        "%pip install tabulate\n",
        "\n",
        "# To plot graphs and heatmaps\n",
        "%pip install seaborn\n",
        "%pip install matplotlib\n",
        "%pip install adjustText\n",
        "\n",
        "# To work with intervals in time\n",
        "%pip install python-dateutil\n",
        "\n",
        "# To work with numbers\n",
        "%pip install numpy\n",
        "\n",
        "# To segment customers\n",
        "%pip install jenkspy\n",
        "\n",
        "# To visualise on a map\n",
        "%pip install plotly\n",
        "%pip install geopy\n",
        "%pip install kaleido"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b74237f",
      "metadata": {
        "id": "8b74237f"
      },
      "source": [
        "#### Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c483088",
      "metadata": {
        "id": "2c483088"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import numpy as np\n",
        "import jenkspy\n",
        "from adjustText import adjust_text\n",
        "from geopy.geocoders import Nominatim\n",
        "import time\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac521fb",
      "metadata": {
        "id": "7ac521fb"
      },
      "source": [
        "### Loading the Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18d4c541",
      "metadata": {
        "id": "18d4c541"
      },
      "outputs": [],
      "source": [
        "FOLDER_URL = 'https://drive.google.com/drive/folders/1FcrdY8uZLE04-U5K2dqnjhDJVenFwGlk' # The Google Drive folder URL\n",
        "DOWNLOAD_DIRECTORY = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Dataset\")) # The directory where the downloaded CSVs will be stored, you can adjust it to your choice but all further analysis will be done based on this directory structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19eb1246",
      "metadata": {
        "id": "19eb1246"
      },
      "outputs": [],
      "source": [
        "# This snippet will download all the contents from the Google Drive Folder\n",
        "\n",
        "# Make the download directory if it doesn't exist\n",
        "os.makedirs(DOWNLOAD_DIRECTORY, exist_ok=True)\n",
        "\n",
        "# Download all the contents of the Google Drive folder\n",
        "gdown.download_folder(url=FOLDER_URL, output=DOWNLOAD_DIRECTORY, quiet=False, use_cookies=False)\n",
        "\n",
        "# Delete all of the non-CSV files\n",
        "for filename in os.listdir(DOWNLOAD_DIRECTORY):\n",
        "    if not filename.lower().endswith(\".csv\"):\n",
        "        file_path = os.path.join(DOWNLOAD_DIRECTORY , filename)\n",
        "        os.remove(file_path)\n",
        "        display(Markdown(f\"Removed non-CSV file: {filename}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8df272cd",
      "metadata": {
        "id": "8df272cd"
      },
      "outputs": [],
      "source": [
        "# This snippet will load all the CSVs into dataframes\n",
        "\n",
        "dataset = {} # The dataframes will be stored in a dictionary to make it easier to loop through all of them\n",
        "\n",
        "for filename in os.listdir(DOWNLOAD_DIRECTORY):\n",
        "    if filename.endswith('.csv'):\n",
        "        key = os.path.splitext(filename)[0] # Extracting the key for each file where the key is the filename without the .csv\n",
        "        file_path = os.path.join(DOWNLOAD_DIRECTORY, filename) # Determining the path of each file in the DOWNLOAD_DIRECTORY\n",
        "        df = pd.read_csv(file_path) # Reading each CSV into a dataframe\n",
        "        dataset[key] = df\n",
        "        display(Markdown(f\"Loaded: `{filename}` -> key=`'{key}'`\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "214a5808",
      "metadata": {
        "id": "214a5808"
      },
      "source": [
        "####  Viewing the First Few Rows of each Table in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064498af",
      "metadata": {
        "id": "064498af"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\"The first 5 rows of each table in the dataset:\"))\n",
        "for key, df in dataset.items():\n",
        "    display(Markdown(f\"##### {key}\"))\n",
        "    display(Markdown(df.head().to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71603420",
      "metadata": {
        "id": "71603420"
      },
      "source": [
        "### Checking the Shape of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ca9888",
      "metadata": {
        "id": "16ca9888"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\"The following table shows how many rows and columns are in each table of the dataset:\"))\n",
        "markdown_text = \"|Table|# Rows|# Columns| \\n |-----|-------|---------| \\n\"\n",
        "for key, df in dataset.items():\n",
        "    markdown_text += f\"|{key}|{df.shape[0]}|{df.shape[1]}|\\n\" # The shape method shows the size of the dataframe\n",
        "display(Markdown(markdown_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2200ecb4",
      "metadata": {
        "id": "2200ecb4"
      },
      "source": [
        "### Displaying Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21eb4b58",
      "metadata": {
        "id": "21eb4b58"
      },
      "outputs": [],
      "source": [
        "for key, df in dataset.items():\n",
        "    display(Markdown(f'Table information for {key}:'))\n",
        "    df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c00092",
      "metadata": {
        "id": "19c00092"
      },
      "source": [
        "### Checking for Duplicate Values in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e649c6",
      "metadata": {
        "id": "e3e649c6"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\"The below table shows the number of duplicate rows for each table in the dataset:\"))\n",
        "markdown_text = '|Table|Duplicate Rows| \\n |----|------| \\n'\n",
        "for key, df in dataset.items():\n",
        "    markdown_text += f'|{key}|{len(df[df.duplicated()])}| \\n' # The duplicated() method shows which rows are duplicate\n",
        "display(Markdown(markdown_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1767f205",
      "metadata": {
        "id": "1767f205"
      },
      "source": [
        "### Checking for Missing / Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd46747",
      "metadata": {
        "id": "9fd46747"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\"The below tables will show how many missing values in each of column of each table:\"))\n",
        "for key, df in dataset.items():\n",
        "    display(Markdown(f\"##### {key}\"))\n",
        "    missing_values = df.isnull().sum()\n",
        "    markdown_table = missing_values.to_frame().reset_index()  # This is done so the output can be shown in markdown format\n",
        "    markdown_table.columns = ['Column Name', '# of Missing Values']\n",
        "    display(Markdown(markdown_table.to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34557f10",
      "metadata": {
        "id": "34557f10"
      },
      "outputs": [],
      "source": [
        "# Visualising the missing values of each table\n",
        "for key, df in dataset.items():\n",
        "    plt.figure(figsize = (6,4))\n",
        "    sns.heatmap(df.isnull(), cbar=False)\n",
        "    plt.title(f\"Missing values Heatmap for {key}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e87e59",
      "metadata": {
        "id": "98e87e59"
      },
      "source": [
        "### Summary of Dataset Observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9603bcf8",
      "metadata": {
        "id": "9603bcf8"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\"#### Observations about the Dataset:\"))\n",
        "\n",
        "# Duplicate Rows\n",
        "duplicate_count = 0\n",
        "for df in dataset.values():\n",
        "    duplicate_count += len(df[df.duplicated()])\n",
        "if duplicate_count == 0:\n",
        "    display(Markdown(\"- None of the tables have any duplicate rows.\"))\n",
        "else:\n",
        "    markdown_text = \"- The following tables have duplicate rows: \\n\"\n",
        "    for key, df in dataset.items():\n",
        "        if len(df[df.duplicated()]) > 0:\n",
        "            markdown_text += f'\\t {key} \\n'\n",
        "\n",
        "# Missing Values\n",
        "missing_count = 0\n",
        "for df in dataset.values():\n",
        "    missing_count += (df.isnull().sum()).sum()\n",
        "if missing_count == 0:\n",
        "    display(Markdown(\"- None of the tables have any missing values in their columns.\"))\n",
        "else:\n",
        "    missing_df = pd.DataFrame({'Table': [], 'Column': [], 'Missing Values': []})\n",
        "    for key, df in dataset.items():\n",
        "        missing_values = df.isnull().sum()\n",
        "        missing_values = missing_values[missing_values > 0]\n",
        "        missing_values = missing_values.reset_index()\n",
        "        missing_values.columns = ['Column', 'Missing Values']\n",
        "        missing_values['Table'] = key\n",
        "        missing_values = missing_values[['Table', 'Column', 'Missing Values']]\n",
        "        missing_df = pd.concat([missing_df, missing_values], ignore_index=True)\n",
        "    display(Markdown(\"- Below is a table which summarises which columns have missing values:\"))\n",
        "    display(Markdown(missing_df.to_markdown(index=False)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d9643a",
      "metadata": {
        "id": "92d9643a"
      },
      "source": [
        "There are 3 columns in the dataset which have null values in them.\n",
        "- `MiddleInitial` will not have any imputed values as there is no significance in the column.\n",
        "- `SalesDate` will be ignored for the analysis which involves time otherwise it will be left as is as only $0.97%$ of the values are missing.\n",
        "- The missing value in `CountryCode` will be filled by assigning our own code to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6182e32",
      "metadata": {
        "id": "e6182e32"
      },
      "outputs": [],
      "source": [
        "country = dataset['countries'][dataset['countries']['CountryCode'].isnull()]\n",
        "display(Markdown(country.to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10aea285",
      "metadata": {
        "id": "10aea285"
      },
      "source": [
        "We will assign the code `AL` for Australia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "196fcee4",
      "metadata": {
        "id": "196fcee4"
      },
      "outputs": [],
      "source": [
        "dataset['countries'].loc[dataset['countries']['CountryID'] == 146, 'CountryCode'] = 'AL' # Using the .loc() method to identify the row with `CountryName` as 'Australia'.\n",
        "display(Markdown(dataset['countries'][dataset['countries']['CountryID'] == 146].to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Inconsistencies"
      ],
      "metadata": {
        "id": "JVVUnt4vJl-h"
      },
      "id": "JVVUnt4vJl-h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Product - Category Mapping"
      ],
      "metadata": {
        "id": "xpVAxW0OJp32"
      },
      "id": "xpVAxW0OJp32"
    },
    {
      "cell_type": "markdown",
      "id": "f4a23f9b",
      "metadata": {
        "id": "f4a23f9b"
      },
      "source": [
        "When viewing the sample tables in [Viewing the First Few Rows of each Table in the Dataset](#viewing-the-first-few-rows-of-each-table-in-the-dataset) it can be seen that logically the product-mapping category is incorrect. To confirm this, let's take a deeper look into the mapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b57ad1",
      "metadata": {
        "id": "57b57ad1"
      },
      "outputs": [],
      "source": [
        "product_category = pd.merge(left=dataset['products'],\n",
        "                            right=dataset['categories'],\n",
        "                            on='CategoryID',\n",
        "                            how='left')\n",
        "product_category = product_category[['ProductID', 'ProductName', 'CategoryID', 'CategoryName']]\n",
        "display(Markdown(product_category.head(50).to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb2f9b91",
      "metadata": {
        "id": "eb2f9b91"
      },
      "source": [
        "We can easily see that some products, for e.g. ProductIDs 3, 45 and 49 are incorrectly categorised and there are many more (Onions - Cippolini is categorised as poultry but it should be produce). Also for example, ProductID 40: Cocktail Napkin Blue does not fit into any category. To fix this issue, a proper rule based classification would need to be done to ensure better product-category mapping and the addition of another category called `Uncategorised` to handle products that don't belong in any of these."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra category in categories\n",
        "dataset['categories'].loc[len(dataset['categories'])] = [12, 'Uncategorised']\n",
        "display(Markdown(dataset['categories'].tail().to_markdown(index=False)))"
      ],
      "metadata": {
        "id": "Z1wPYkb4r12C"
      },
      "id": "Z1wPYkb4r12C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to map products properly into their categories\n",
        "\n",
        "# The following dictionary was genereated by ChatGPT as keyword based classification was ambiguous\n",
        "product_categoryID = {\n",
        "  \"Flour - Whole Wheat\": 8,\n",
        "  \"Cookie Chocolate Chip With\": 1,\n",
        "  \"Onions - Cippolini\": 11,\n",
        "  \"Sauce - Gravy, Au Jus, Mix\": 11,\n",
        "  \"Artichokes - Jerusalem\": 11,\n",
        "  \"Wine - Magnotta - Cab Sauv\": 5,\n",
        "  \"Table Cloth - 53x69 Colour\": 12,\n",
        "  \"Halibut - Steaks\": 6,\n",
        "  \"Rabbit - Whole\": 7,\n",
        "  \"Scampi Tail\": 12,\n",
        "  \"Garbage Bags - Clear\": 12,\n",
        "  \"Ezy Change Mophandle\": 12,\n",
        "  \"Water, Tap\": 5,\n",
        "  \"Beef - Top Sirloin\": 7,\n",
        "  \"Spoon - Soup, Plastic\": 12,\n",
        "  \"Kellogs Special K Cereal\": 3,\n",
        "  \"Wine - White, Mosel Gold\": 5,\n",
        "  \"Lamb - Whole, Fresh\": 7,\n",
        "  \"Tea - Earl Grey\": 5,\n",
        "  \"Chocolate - Feathers\": 1,\n",
        "  \"Kiwi\": 11,\n",
        "  \"Rice - Jasmine Sented\": 8,\n",
        "  \"Crab - Imitation Flakes\": 2,\n",
        "  \"Beer - Alexander Kieths, Pale Ale\": 5,\n",
        "  \"Soupcontfoam16oz 116con\": 12,\n",
        "  \"Squid U5 - Thailand\": 6,\n",
        "  \"Chocolate - Compound Coating\": 1,\n",
        "  \"Sobe - Tropical Energy\": 5,\n",
        "  \"Spinach - Baby\": 11,\n",
        "  \"Cheese - Brie, Triple Creme\": 4,\n",
        "  \"Yeast Dry - Fermipan\": 12,\n",
        "  \"Lettuce - Treviso\": 11,\n",
        "  \"Beans - Wax\": 11,\n",
        "  \"Mustard Prepared\": 12,\n",
        "  \"Water - Mineral, Natural\": 5,\n",
        "  \"Table Cloth 54x72 White\": 12,\n",
        "  \"Nut - Pistachio, Shelled\": 11,\n",
        "  \"Sage - Ground\": 11,\n",
        "  \"Dried Figs\": 11,\n",
        "  \"Cocktail Napkin Blue\": 12,\n",
        "  \"Cup - 6oz, Foam\": 12,\n",
        "  \"Bread - Raisin Walnut Oval\": 8,\n",
        "  \"Sponge Cake Mix - Chocolate\": 1,\n",
        "  \"Wine - White, Colubia Cresh\": 5,\n",
        "  \"Beef - Ground Medium\": 7,\n",
        "  \"Lambcasing\": 7,\n",
        "  \"Thyme - Lemon, Fresh\": 11,\n",
        "  \"Pecan Raisin - Tarts\": 1,\n",
        "  \"Bacardi Breezer - Tropical\": 5,\n",
        "  \"Pork - Kidney\": 7,\n",
        "  \"Wine - Crozes Hermitage E.\": 5,\n",
        "  \"Turnip - White, Organic\": 11,\n",
        "  \"Cassis\": 5,\n",
        "  \"Liners - Banana, Paper\": 11,\n",
        "  \"Cinnamon Buns Sticky\": 1,\n",
        "  \"Chips Potato Salt Vinegar 43g\": 11,\n",
        "  \"Sausage - Breakfast\": 7,\n",
        "  \"Dc Hikiage Hira Huba\": 12,\n",
        "  \"Pastry - Butterscotch Baked\": 1,\n",
        "  \"Pepper - Paprika, Hungarian\": 11,\n",
        "  \"Sardines\": 6,\n",
        "  \"Pears - Bosc\": 11,\n",
        "  \"Cake - Mini Cheesecake\": 1,\n",
        "  \"Vinegar - Sherry\": 12,\n",
        "  \"Brandy - Bar\": 5,\n",
        "  \"Pie Filling - Cherry\": 11,\n",
        "  \"Wine - Sogrape Mateus Rose\": 5,\n",
        "  \"Beets - Candy Cane, Organic\": 11,\n",
        "  \"Raspberries - Fresh\": 11,\n",
        "  \"Squid - Tubes / Tenticles 10/20\": 6,\n",
        "  \"Cheese - Wine\": 4,\n",
        "  \"Bar - Granola Trail Mix Fruit Nut\": 11,\n",
        "  \"Appetizer - Sausage Rolls\": 7,\n",
        "  \"Carbonated Water - Cherry\": 5,\n",
        "  \"Chef Hat 20cm\": 12,\n",
        "  \"Wine - Fume Blanc Fetzer\": 5,\n",
        "  \"Potatoes - Idaho 100 Count\": 11,\n",
        "  \"Wine - Magnotta - Belpaese\": 5,\n",
        "  \"Pasta - Penne, Rigate, Dry\": 8,\n",
        "  \"Wasabi Powder\": 12,\n",
        "  \"Cookies - Assorted\": 1,\n",
        "  \"Jolt Cola - Electric Blue\": 5,\n",
        "  \"Lamb - Ground\": 7,\n",
        "  \"Peas - Frozen\": 11,\n",
        "  \"Cheese - Parmesan Cubes\": 4,\n",
        "  \"Longos - Grilled Chicken With\": 9,\n",
        "  \"Wine - Pinot Noir Latour\": 5,\n",
        "  \"Remy Red\": 5,\n",
        "  \"Beef - Ground, Extra Lean, Fresh\": 7,\n",
        "  \"Flavouring - Orange\": 11,\n",
        "  \"General Purpose Trigger\": 12,\n",
        "  \"Wine - Red, Colio Cabernet\": 5,\n",
        "  \"Bandage - Fexible 1x3\": 12,\n",
        "  \"V8 - Berry Blend\": 5,\n",
        "  \"Beans - Kidney White\": 11,\n",
        "  \"Cheese - Bocconcini\": 4,\n",
        "  \"Veal - Inside\": 7,\n",
        "  \"Shrimp - 31/40\": 2,\n",
        "  \"Mustard - Seed\": 11,\n",
        "  \"Pork - Loin, Bone - In\": 7,\n",
        "  \"Soup - Campbells, Lentil\": 12,\n",
        "  \"Rosemary - Primerba, Paste\": 11,\n",
        "  \"Cream Of Tartar\": 1,\n",
        "  \"Tia Maria\": 5,\n",
        "  \"Ecolab - Mikroklene 4/4 L\": 12,\n",
        "  \"Pickerel - Fillets\": 6,\n",
        "  \"Bread - French Baquette\": 8,\n",
        "  \"Pasta - Orecchiette\": 8,\n",
        "  \"Muffin - Zero Transfat\": 1,\n",
        "  \"Black Currants\": 11,\n",
        "  \"Scallops 60/80 Iqf\": 2,\n",
        "  \"Browning Caramel Glace\": 1,\n",
        "  \"Ocean Spray - Kiwi Strawberry\": 5,\n",
        "  \"Veal - Osso Bucco\": 7,\n",
        "  \"Ocean Spray - Ruby Red\": 5,\n",
        "  \"Steam Pan - Half Size Deep\": 12,\n",
        "  \"Ketchup - Tomato\": 11,\n",
        "  \"Garbag Bags - Black\": 12,\n",
        "  \"Soup Campbells - Italian Wedding\": 12,\n",
        "  \"Water - Spring Water 500ml\": 5,\n",
        "  \"Muffin Batt - Blueberry Passion\": 1,\n",
        "  \"Table Cloth 62x114 White\": 12,\n",
        "  \"Oil - Shortening - All - Purpose\": 12,\n",
        "  \"Macaroons - Two Bite Choc\": 1,\n",
        "  \"Nut - Chestnuts, Whole\": 11,\n",
        "  \"Crackers - Trio\": 12,\n",
        "  \"Island Oasis - Mango Daiquiri\": 5,\n",
        "  \"Coffee - Irish Cream\": 5,\n",
        "  \"Chicken - Soup Base\": 9,\n",
        "  \"Beef Wellington\": 7,\n",
        "  \"Anchovy Paste - 56 G Tube\": 6,\n",
        "  \"Beer - Blue\": 5,\n",
        "  \"Beef - Top Sirloin - Aaa\": 7,\n",
        "  \"Wine - Toasted Head\": 5,\n",
        "  \"Wiberg Super Cure\": 12,\n",
        "  \"Vol Au Vents\": 12,\n",
        "  \"Wine - White, Schroder And Schyl\": 5,\n",
        "  \"Rum - Coconut, Malibu\": 5,\n",
        "  \"Chicken - Wieners\": 9,\n",
        "  \"Oregano - Dry, Rubbed\": 11,\n",
        "  \"Tea - Herbal Sweet Dreams\": 5,\n",
        "  \"Pork - Bacon, Double Smoked\": 7,\n",
        "  \"Watercress\": 11,\n",
        "  \"Placemat - Scallop, White\": 12,\n",
        "  \"Wine - Chardonnay South\": 5,\n",
        "  \"Bananas\": 11,\n",
        "  \"Cheese - Mozzarella\": 4,\n",
        "  \"Beer - Sleemans Cream Ale\": 5,\n",
        "  \"Zucchini - Yellow\": 11,\n",
        "  \"Langers - Ruby Red Grapfruit\": 11,\n",
        "  \"Mushrooms - Black, Dried\": 11,\n",
        "  \"Lentils - Red, Dry\": 11,\n",
        "  \"Arizona - Green Tea\": 5,\n",
        "  \"Ice Cream Bar - Drumstick\": 4,\n",
        "  \"Peas - Pigeon, Dry\": 11,\n",
        "  \"Sprouts - Alfalfa\": 11,\n",
        "  \"Juice - Cranberry, 341 Ml\": 5,\n",
        "  \"Apricots Fresh\": 11,\n",
        "  \"Eggplant - Asian\": 11,\n",
        "  \"Beef Ground Medium\": 7,\n",
        "  \"Longos - Chicken Wings\": 9,\n",
        "  \"Sauce - Demi Glace\": 12,\n",
        "  \"Tomatoes Tear Drop\": 11,\n",
        "  \"Loquat\": 11,\n",
        "  \"Bread Crumbs - Japanese Style\": 8,\n",
        "  \"Tray - 16in Rnd Blk\": 12,\n",
        "  \"Knife Plastic - White\": 12,\n",
        "  \"Milk - 2%\": 4,\n",
        "  \"Water - Aquafina Vitamin\": 5,\n",
        "  \"Initation Crab Meat\": 2,\n",
        "  \"Gloves - Goldtouch Disposable\": 12,\n",
        "  \"Sherry - Dry\": 5,\n",
        "  \"Rosemary - Dry\": 11,\n",
        "  \"Guinea Fowl\": 9,\n",
        "  \"Oil - Safflower\": 12,\n",
        "  \"Smirnoff Green Apple Twist\": 5,\n",
        "  \"Coconut - Shredded, Sweet\": 11,\n",
        "  \"Pernod\": 5,\n",
        "  \"Yoghurt Tubes\": 4,\n",
        "  \"Chocolate - Dark\": 1,\n",
        "  \"Phyllo Dough\": 8,\n",
        "  \"Campari\": 5,\n",
        "  \"Spice - Peppercorn Melange\": 11,\n",
        "  \"Hersey Shakes\": 4,\n",
        "  \"Foam Dinner Plate\": 12,\n",
        "  \"Muffin Mix - Blueberry\": 1,\n",
        "  \"Pepper - Black, Whole\": 11,\n",
        "  \"Cup - Translucent 7 Oz Clear\": 12,\n",
        "  \"Bread - Roll, Soft White Round\": 8,\n",
        "  \"Cake - Cake Sheet Macaroon\": 1,\n",
        "  \"Hickory Smoke, Liquid\": 12,\n",
        "  \"Wine - Magnotta, Merlot Sr Vqa\": 5,\n",
        "  \"Veal - Inside, Choice\": 7,\n",
        "  \"Lettuce - Frisee\": 11,\n",
        "  \"Beets - Mini Golden\": 11,\n",
        "  \"Longos - Grilled Salmon With Bbq\": 6,\n",
        "  \"Mussels - Cultivated\": 2,\n",
        "  \"Lime Cordial - Roses\": 11,\n",
        "  \"Pork - Hock And Feet Attached\": 7,\n",
        "  \"Garlic - Peeled\": 11,\n",
        "  \"Grenadine\": 5,\n",
        "  \"Bay Leaf\": 11,\n",
        "  \"Chicken - Leg, Boneless\": 9,\n",
        "  \"Scallop - St. Jaques\": 2,\n",
        "  \"Turkey - Whole, Fresh\": 9,\n",
        "  \"Cocoa Butter\": 1,\n",
        "  \"Coffee - Hazelnut Cream\": 4,\n",
        "  \"Mushroom - Trumpet, Dry\": 11,\n",
        "  \"Sugar - Fine\": 1,\n",
        "  \"Cheese - Brie,danish\": 4,\n",
        "  \"Wine - Prosecco Valdobiaddene\": 5,\n",
        "  \"Curry Paste - Madras\": 12,\n",
        "  \"Pate - Cognac\": 12,\n",
        "  \"French Pastry - Mini Chocolate\": 1,\n",
        "  \"Veal - Brisket, Provimi,bnls\": 7,\n",
        "  \"Scallops - 10/20\": 2,\n",
        "  \"Bread - Multigrain\": 8,\n",
        "  \"Barramundi\": 6,\n",
        "  \"Assorted Desserts\": 1,\n",
        "  \"Meldea Green Tea Liquor\": 5,\n",
        "  \"Bread Crumbs - Panko\": 8,\n",
        "  \"Sole - Dover, Whole, Fresh\": 6,\n",
        "  \"Pail With Metal Handle 16l White\": 12,\n",
        "  \"Flour - Pastry\": 8,\n",
        "  \"Wine - Charddonnay Errazuriz\": 5,\n",
        "  \"Chestnuts - Whole,canned\": 11,\n",
        "  \"Cheese - Taleggio D.o.p.\": 4,\n",
        "  \"Sauce - Hollandaise\": 12,\n",
        "  \"Bread - Hot Dog Buns\": 8,\n",
        "  \"Wine - Cahors Ac 2000, Clos\": 5,\n",
        "  \"Crush - Cream Soda\": 5,\n",
        "  \"Quiche Assorted\": 12,\n",
        "  \"Duck - Breast\": 9,\n",
        "  \"Tofu - Firm\": 12,\n",
        "  \"Bread - English Muffin\": 8,\n",
        "  \"Tomato - Tricolor Cherry\": 11,\n",
        "  \"Mayonnaise - Individual Pkg\": 12,\n",
        "  \"Garlic\": 11,\n",
        "  \"Soup - Campbells, Cream Of\": 12,\n",
        "  \"Wine - Chablis 2003 Champs\": 5,\n",
        "  \"Cheese - Cheddarsliced\": 4,\n",
        "  \"Thermometer Digital\": 12,\n",
        "  \"Sun - Dried Tomatoes\": 11,\n",
        "  \"Beef - Rib Eye Aaa\": 7,\n",
        "  \"Grouper - Fresh\": 6,\n",
        "  \"Ice Cream Bar - Hageen Daz To\": 4,\n",
        "  \"Juice - Apple Cider\": 5,\n",
        "  \"Beef - Inside Round\": 7,\n",
        "  \"Cookie Dough - Double\": 1,\n",
        "  \"Soup - Campbells, Beef Barley\": 7,\n",
        "  \"Oranges - Navel, 72\": 11,\n",
        "  \"Nantucket - Pomegranate Pear\": 5,\n",
        "  \"Wanton Wrap\": 8,\n",
        "  \"Soup - Canadian Pea, Dry Mix\": 11,\n",
        "  \"Kellogs All Bran Bars\": 3,\n",
        "  \"Soup Knorr Chili With Beans\": 11,\n",
        "  \"Pasta - Detalini, White, Fresh\": 8,\n",
        "  \"Tea - English Breakfast\": 5,\n",
        "  \"Veal - Eye Of Round\": 7,\n",
        "  \"Yogurt - Blueberry, 175 Gr\": 4,\n",
        "  \"Chinese Foods - Chicken\": 9,\n",
        "  \"Bagel - Plain\": 8,\n",
        "  \"Soupfoamcont12oz 112con\": 12,\n",
        "  \"Juice - V8 Splash\": 5,\n",
        "  \"Mushroom - Porcini, Dry\": 11,\n",
        "  \"Clam Nectar\": 2,\n",
        "  \"Grapes - Red\": 11,\n",
        "  \"Vanilla Beans\": 11,\n",
        "  \"Wine - Blue Nun Qualitatswein\": 5,\n",
        "  \"Cheese Cloth No 100\": 4,\n",
        "  \"Banana - Leaves\": 11,\n",
        "  \"Chocolate - Semi Sweet, Calets\": 1,\n",
        "  \"Bandage - Flexible Neon\": 12,\n",
        "  \"Papayas\": 11,\n",
        "  \"Corn Meal\": 8,\n",
        "  \"Snapple - Iced Tea Peach\": 5,\n",
        "  \"Sea Bass - Whole\": 6,\n",
        "  \"Apricots - Halves\": 11,\n",
        "  \"Beef - Texas Style Burger\": 7,\n",
        "  \"Onion Powder\": 11,\n",
        "  \"Bar Mix - Pina Colada, 355 Ml\": 5,\n",
        "  \"Lemonade - Natural, 591 Ml\": 5,\n",
        "  \"Bread Fig And Almond\": 8,\n",
        "  \"Beer - Rickards Red\": 5,\n",
        "  \"Cheese - Mix\": 4,\n",
        "  \"Beef - Prime Rib Aaa\": 7,\n",
        "  \"Bread - Italian Roll With Herbs\": 8,\n",
        "  \"Orange - Canned, Mandarin\": 11,\n",
        "  \"Sword Pick Asst\": 12,\n",
        "  \"Sauce - Rosee\": 12,\n",
        "  \"Crab - Dungeness, Whole\": 2,\n",
        "  \"Turkey - Oven Roast Breast\": 9,\n",
        "  \"Garlic - Elephant\": 11,\n",
        "  \"Wine - Alsace Gewurztraminer\": 5,\n",
        "  \"Ice - Clear, 300 Lb For Carving\": 12,\n",
        "  \"Wine - Valpolicella Masi\": 5,\n",
        "  \"Hinge W Undercut\": 12,\n",
        "  \"Pop Shoppe Cream Soda\": 4,\n",
        "  \"Fuji Apples\": 11,\n",
        "  \"Beans - Kidney, Canned\": 11,\n",
        "  \"Beer - Labatt Blue\": 5,\n",
        "  \"Doilies - 5, Paper\": 12,\n",
        "  \"Cod - Black Whole Fillet\": 6,\n",
        "  \"Banana Turning\": 11,\n",
        "  \"Pastry - Cheese Baked Scones\": 1,\n",
        "  \"Pepper - White, Ground\": 11,\n",
        "  \"Foam Cup 6 Oz\": 12,\n",
        "  \"Tea - Decaf Lipton\": 5,\n",
        "  \"Muffin Batt - Choc Chk\": 1,\n",
        "  \"Coffee - Dark Roast\": 5,\n",
        "  \"Wonton Wrappers\": 8,\n",
        "  \"Salmon - Sockeye Raw\": 6,\n",
        "  \"Veal - Slab Bacon\": 7,\n",
        "  \"Salmon Steak - Cohoe 8 Oz\": 6,\n",
        "  \"Wine - Gato Negro Cabernet\": 5,\n",
        "  \"Cheese - Victor Et Berthold\": 4,\n",
        "  \"Water - Green Tea Refresher\": 5,\n",
        "  \"Ecolab - Solid Fusion\": 12,\n",
        "  \"Towels - Paper / Kraft\": 12,\n",
        "  \"Yogurt - French Vanilla\": 4,\n",
        "  \"Potatoes - Instant, Mashed\": 11,\n",
        "  \"Onions - Vidalia\": 11,\n",
        "  \"Extract - Lemon\": 11,\n",
        "  \"Apricots - Dried\": 11,\n",
        "  \"Halibut - Fletches\": 6,\n",
        "  \"Appetizer - Mushroom Tart\": 1,\n",
        "  \"Appetizer - Mini Egg Roll, Shrimp\": 2,\n",
        "  \"Tuna - Salad Premix\": 6,\n",
        "  \"Pork - Loin, Center Cut\": 7,\n",
        "  \"Olives - Kalamata\": 11,\n",
        "  \"Cookies Cereal Nut\": 1,\n",
        "  \"Bouq All Italian - Primerba\": 12,\n",
        "  \"Cheese - Cottage Cheese\": 4,\n",
        "  \"Ecolab - Lime - A - Way 4/4 L\": 5,\n",
        "  \"Oil - Shortening,liqud, Fry\": 12,\n",
        "  \"Broom - Corn\": 12,\n",
        "  \"Bread - Rye\": 8,\n",
        "  \"Cheese - Camembert\": 4,\n",
        "  \"Beef - Striploin Aa\": 7,\n",
        "  \"Veal - Sweetbread\": 7,\n",
        "  \"Bread - Roll, Canadian Dinner\": 8,\n",
        "  \"Mangoes\": 11,\n",
        "  \"Otomegusa Dashi Konbu\": 12,\n",
        "  \"Sausage - Liver\": 7,\n",
        "  \"Bread - Calabrese Baguette\": 8,\n",
        "  \"Cheese - Parmesan Grated\": 4,\n",
        "  \"Pail For Lid 1537\": 12,\n",
        "  \"Pasta - Cheese / Spinach Bauletti\": 8,\n",
        "  \"Puree - Mocha\": 12,\n",
        "  \"Isomalt\": 12,\n",
        "  \"Hot Chocolate - Individual\": 5,\n",
        "  \"Beef - Tenderlion, Center Cut\": 7,\n",
        "  \"Milk Powder\": 4,\n",
        "  \"Crackers Cheez It\": 12,\n",
        "  \"Olives - Stuffed\": 11,\n",
        "  \"Dc - Frozen Momji\": 12,\n",
        "  \"Tilapia - Fillets\": 6,\n",
        "  \"Cheese - Boursin, Garlic / Herbs\": 4,\n",
        "  \"Rice - Long Grain\": 8,\n",
        "  \"Wine - Hardys Bankside Shiraz\": 5,\n",
        "  \"Coffee Decaf Colombian\": 5,\n",
        "  \"Cumin - Whole\": 11,\n",
        "  \"Cornflakes\": 3,\n",
        "  \"Cattail Hearts\": 11,\n",
        "  \"Wine - Red, Harrow Estates, Cab\": 5,\n",
        "  \"Tahini Paste\": 12,\n",
        "  \"Bread - Italian Corn Meal Poly\": 8,\n",
        "  \"Flour - Teff\": 8,\n",
        "  \"Rambutan\": 11,\n",
        "  \"Muffin - Carrot Individual Wrap\": 1,\n",
        "  \"Creme De Banane - Marie\": 5,\n",
        "  \"Wine - Two Oceans Cabernet\": 5,\n",
        "  \"Beef - Montreal Smoked Brisket\": 7,\n",
        "  \"Jagermeister\": 5,\n",
        "  \"Snapple Lemon Tea\": 5,\n",
        "  \"Pasta - Angel Hair\": 8,\n",
        "  \"Wine - Red, Cooking\": 5,\n",
        "  \"Bread Foccacia Whole\": 8,\n",
        "  \"Smoked Paprika\": 11,\n",
        "  \"Wine - White Cab Sauv.on\": 5,\n",
        "  \"Vaccum Bag 10x13\": 12,\n",
        "  \"Soup - Campbells Bean Medley\": 11,\n",
        "  \"Cake - Box Window 10x10x2.5\": 1,\n",
        "  \"Fond - Neutral\": 12,\n",
        "  \"Pork - Back, Short Cut, Boneless\": 7,\n",
        "  \"Sprouts - Baby Pea Tendrils\": 11,\n",
        "  \"Fondant - Icing\": 1,\n",
        "  \"Table Cloth 120 Round White\": 12,\n",
        "  \"Pomello\": 11,\n",
        "  \"Seedlings - Mix, Organic\": 11,\n",
        "  \"Bread - Bistro White\": 8,\n",
        "  \"Puree - Passion Fruit\": 11,\n",
        "  \"Olive - Spread Tapenade\": 11,\n",
        "  \"Rum - Mount Gay Eclipes\": 5,\n",
        "  \"Juice - Lime\": 5,\n",
        "  \"Tea - Jasmin Green\": 5,\n",
        "  \"Juice - Happy Planet\": 5,\n",
        "  \"Wine - Wyndham Estate Bin 777\": 5,\n",
        "  \"Berry Brulee\": 11,\n",
        "  \"Carbonated Water - Blackcherry\": 5,\n",
        "  \"Tart Shells - Sweet, 4\": 1,\n",
        "  \"Butter - Unsalted\": 4,\n",
        "  \"Liners - Baking Cups\": 12,\n",
        "  \"Pants Custom Dry Clean\": 12,\n",
        "  \"Pastry - Raisin Muffin - Mini\": 1,\n",
        "  \"Shrimp - Baby, Warm Water\": 2,\n",
        "  \"Pepsi - Diet, 355 Ml\": 5,\n",
        "  \"Blueberries\": 11,\n",
        "  \"Skirt - 29 Foot\": 12,\n",
        "  \"Fenngreek Seed\": 11,\n",
        "  \"Durian Fruit\": 11,\n",
        "  \"Lettuce - California Mix\": 11,\n",
        "  \"Ice Cream Bar - Oreo Cone\": 4,\n",
        "  \"Sauerkraut\": 11,\n",
        "  \"Mussels - Frozen\": 2,\n",
        "  \"Baking Powder\": 12,\n",
        "  \"Lamb - Pieces, Diced\": 7,\n",
        "  \"Truffle Cups - Brown\": 12,\n",
        "  \"Pork - Belly Fresh\": 7,\n",
        "  \"Whmis - Spray Bottle Trigger\": 12,\n",
        "  \"Soup V8 Roasted Red Pepper\": 5,\n",
        "  \"Garlic - Primerba, Paste\": 11,\n",
        "  \"Fish - Scallops, Cold Smoked\": 2,\n",
        "  \"Vinegar - Tarragon\": 12,\n",
        "  \"Wine - Redchard Merritt\": 5,\n",
        "  \"Scallops - Live In Shell\": 2,\n",
        "  \"Wine - Vineland Estate Semi - Dry\": 5,\n",
        "  \"Wine - Ruffino Chianti\": 5,\n",
        "  \"Beef - Short Loin\": 7,\n",
        "  \"Milk - 1%\": 4,\n",
        "  \"Muffin Chocolate Individual Wrap\": 1,\n",
        "  \"Beer - Original Organic Lager\": 5,\n",
        "  \"Beans - Kidney, Red Dry\": 11,\n",
        "  \"Cookie - Dough Variety\": 1,\n",
        "  \"Salsify, Organic\": 11,\n",
        "  \"Table Cloth 81x81 White\": 12,\n",
        "  \"Chips Potato All Dressed - 43g\": 11,\n",
        "  \"Juice - Orange\": 5,\n",
        "  \"Beef - Chuck, Boneless\": 7,\n",
        "  \"Pork - Inside\": 7,\n",
        "  \"Blackberries\": 11,\n",
        "  \"Wine - Ej Gallo Sierra Valley\": 5,\n",
        "  \"Lettuce - Spring Mix\": 11,\n",
        "  \"Cheese - Cambozola\": 4,\n",
        "  \"Pastry - Choclate Baked\": 1,\n",
        "  \"Sunflower Seed Raw\": 11,\n",
        "  \"Salmon - Atlantic, Skin On\": 6,\n",
        "  \"Gatorade - Xfactor Berry\": 5,\n",
        "  \"Nantuket Peach Orange\": 5,\n",
        "  \"Wine - Vidal Icewine Magnotta\": 5,\n",
        "  \"Soup - Campbells Tomato Ravioli\": 11,\n",
        "  \"Napkin White - Starched\": 12\n",
        "}\n",
        "\n",
        "dataset['products']['NewCategoryID'] = dataset['products']['ProductName'].map(product_categoryID).fillna(12).astype(int)\n",
        "display(Markdown(dataset['products'].head().to_markdown(index=False)))\n"
      ],
      "metadata": {
        "id": "sGaup_bZsr5_"
      },
      "id": "sGaup_bZsr5_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Class, Resitant Classification"
      ],
      "metadata": {
        "id": "71r07ekRJz9L"
      },
      "id": "71r07ekRJz9L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the definition of the column 'Class' in [Column Definitions](#column-definitions), the values in it should be Standard, Premium, etc. but the given values in the samples seen so far are Medium, Low, etc. And for the 'Resistant' column the definition says that it shows what type of Resistance a product has (e.g. Water-Resistance) but from the sample, the unique values are Durable, Weak, etc. Let's check if the values match the definition."
      ],
      "metadata": {
        "id": "Tuhv6x3WJ23I"
      },
      "id": "Tuhv6x3WJ23I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to check the unique values of the Class and Resistant Columns\n",
        "for col in ['Class', 'Resistant']:\n",
        "  unique_col = dataset['products'][col].unique()\n",
        "  markdown_list = \"\\n\".join(f\"- {item}\" for item in unique_col)\n",
        "  display(Markdown(\"The unique values in the Class column are:\"))\n",
        "  display(Markdown(markdown_list))\n"
      ],
      "metadata": {
        "id": "se6HlbhmKn9g"
      },
      "id": "se6HlbhmKn9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the values in the column do not match the definition and the classification seems arbitrary the column should be dropped."
      ],
      "metadata": {
        "id": "AYV6hkZPL1Bg"
      },
      "id": "AYV6hkZPL1Bg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Class & Resistant column\n",
        "dataset['products'] = dataset['products'].drop(columns=['Class', 'Resistant'])\n",
        "display(Markdown(dataset['products'].head().to_markdown(index=False)))"
      ],
      "metadata": {
        "id": "6Yk9ONlsL-P_"
      },
      "id": "6Yk9ONlsL-P_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5b293e1e",
      "metadata": {
        "id": "5b293e1e"
      },
      "source": [
        "## 2. Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7b52f79",
      "metadata": {
        "id": "c7b52f79"
      },
      "source": [
        "The data types of each column were already determined when the `.info()` method was used for each table in the [Displaying Dataset Information](#displaying-dataset-information) Section. Based on the column definitions in [Column Defintions](#column-definitions). Some columns should have more accurate data types for analysis and query performance purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf5091d",
      "metadata": {
        "id": "7cf5091d"
      },
      "source": [
        "The columns for which data types should be changed are in the table below:\n",
        "\n",
        "|Table|Column|Current Type|Required Type|\n",
        "|-----|------|------------|-------------|\n",
        "|categories|CategoryName|object|category|\n",
        "|cities|CityName|object|string|\n",
        "|countries|CountryName|object|string|\n",
        "|countries|CountryCode|object|string|\n",
        "|customers|FirstName|object|string|\n",
        "|customers|MiddleInitial|object|string|\n",
        "|customers|LastName|object|string|\n",
        "|customers|Address|object|string|\n",
        "|employees|FirstName|object|string|\n",
        "|employees|MiddleInitial|object|string|\n",
        "|employees|LastName|object|string|\n",
        "|employees|BirthDate|object|datetime|\n",
        "|employees|HireDate|object|datetime|\n",
        "|products|ProductName|object|string|\n",
        "|products|Class|object|category|\n",
        "|products|ModifyDate|object|datetime|\n",
        "|products|Resistant|object|category|\n",
        "|products|IsAllergic|object|bool|\n",
        "|sales|SalesDate|object|datetime|\n",
        "|sales|TransactionNumber|object|string|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe006a82",
      "metadata": {
        "id": "fe006a82"
      },
      "outputs": [],
      "source": [
        "# Converting the dtypes to the most optimal for analysis\n",
        "\n",
        "dataset['categories']['CategoryName'] = dataset['categories']['CategoryName'].astype('category')\n",
        "display(Markdown(f\"Converted CategoryName in categories from `object` to `{dataset['categories']['CategoryName'].dtype}`.\"))\n",
        "\n",
        "dataset['cities']['CityName'] = dataset['cities']['CityName'].astype('string')\n",
        "display(Markdown(f\"Converted CityName in cities from `object` to `{dataset['cities']['CityName'].dtype}`.\"))\n",
        "\n",
        "dataset['countries'][['CountryName', 'CountryCode']] = dataset['countries'][['CountryName', 'CountryCode']].astype('string')\n",
        "display(Markdown(f\"Converted CountryName & CountryCode in countries from `object` to `string`.\"))\n",
        "\n",
        "dataset['customers'][['FirstName', 'MiddleInitial', 'LastName', 'Address']] = dataset['customers'][['FirstName', 'MiddleInitial', 'LastName', 'Address']].astype('string')\n",
        "display(Markdown(\"Converted FirstName, MiddleInitial, LastName, Address in customers from `object` to `string`.\"))\n",
        "\n",
        "dataset['employees'][['FirstName', 'MiddleInitial', 'LastName']] = dataset['employees'][['FirstName', 'MiddleInitial', 'LastName']].astype('string')\n",
        "display(Markdown(\"Converted FirstName, MiddleInitial, LastName in employees from `object` to `string`.\"))\n",
        "\n",
        "for col in ['BirthDate', 'HireDate']:\n",
        "    dataset['employees'][col] = pd.to_datetime(dataset['employees'][col])\n",
        "display(Markdown(f\"Converted BirthDate & HireDate in employees from `object` to `datetime`\"))\n",
        "\n",
        "dataset['products']['ProductName'] = dataset['products']['ProductName'].astype('string')\n",
        "display(Markdown(\"Converted ProductName in products from `object` to `string`.\"))\n",
        "\n",
        "dataset['products']['ModifyDate'] = pd.to_datetime(dataset['products']['ModifyDate'])\n",
        "display(Markdown(\"Converted ModifyDate in products from `object` to `datetime`.\"))\n",
        "\n",
        "dataset['products']['IsAllergic'] = dataset['products']['IsAllergic'].astype('bool')\n",
        "display(Markdown(f\"Converted IsAllergic in products from `object` to `{dataset['products']['IsAllergic'].dtype}`.\"))\n",
        "\n",
        "dataset['sales']['SalesDate'] = pd.to_datetime(dataset['sales']['SalesDate'])\n",
        "display(Markdown(\"Converted SalesDate in sales from `object` to `datetime`.\"))\n",
        "\n",
        "dataset['sales']['TransactionNumber'] = dataset['sales']['TransactionNumber'].astype('string')\n",
        "display(Markdown(\"Converted TransactionNumber in sales from `object` to `string`.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0caa881",
      "metadata": {
        "id": "b0caa881"
      },
      "outputs": [],
      "source": [
        "# Summary Statistics for each table in the dataframe\n",
        "display(Markdown(\"### Summary Statistics for each table:\"))\n",
        "for key, df in dataset.items():\n",
        "    display(Markdown(f'#### {key}'))\n",
        "    summary = df.describe(include='all')\n",
        "    print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6679bf07",
      "metadata": {
        "id": "6679bf07"
      },
      "source": [
        "According to the Summary Statistics, all of the values in the TotalPrice column are $0$. This should not be possible. To handle this, the column should be dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "715fecab",
      "metadata": {
        "id": "715fecab"
      },
      "outputs": [],
      "source": [
        "dataset['sales'] = dataset['sales'].drop(columns='TotalPrice')\n",
        "display(Markdown(dataset['sales'].head().to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3259479e",
      "metadata": {
        "id": "3259479e"
      },
      "source": [
        "According to the Summary Statistics, many of the values in the VitalityDays column are $0$. This needs to be investigated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "582bd6e6",
      "metadata": {
        "id": "582bd6e6"
      },
      "outputs": [],
      "source": [
        "display(Markdown(dataset['products'][dataset['products']['VitalityDays'] == 0].to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42df775",
      "metadata": {
        "id": "b42df775"
      },
      "source": [
        "As you can see from the list of product names that most of these items are perishable, so VitalityDays should not be $0$. Thus, we can conclude that the data in this column is unreliable and should be removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2cd14f3",
      "metadata": {
        "id": "f2cd14f3"
      },
      "outputs": [],
      "source": [
        "dataset['products'] = dataset['products'].drop(columns='VitalityDays')\n",
        "display(Markdown(dataset['products'].head().to_markdown()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea810be2",
      "metadata": {
        "id": "ea810be2"
      },
      "source": [
        "## 3. Data Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7728f0",
      "metadata": {
        "id": "3b7728f0"
      },
      "outputs": [],
      "source": [
        "# Code to calculate total sales revenue\n",
        "revenue = pd.merge(left=dataset['sales'],\n",
        "                   right=dataset['products'],\n",
        "                   on='ProductID',\n",
        "                   how='left')\n",
        "revenue = revenue[['TransactionNumber', 'Price', 'Quantity', 'Discount']]\n",
        "revenue['Revenue'] = revenue['Price'] * revenue['Quantity'] * (1 - revenue['Discount'])\n",
        "display(Markdown(\"The total sales revenue can be calculated by breaking down each transaction into its components:\"))\n",
        "display(Markdown(revenue.head().to_markdown(index=False)))\n",
        "\n",
        "# Total Sales Revenue\n",
        "total_sales_revenue = revenue['Revenue'].sum()\n",
        "display(Markdown(f\"The Total Sales Revenue of FreshMart from {dataset['sales']['SalesDate'].min().date()} to {dataset['sales']['SalesDate'].max().date()} is USD {round(total_sales_revenue,2):,}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b53ba6",
      "metadata": {
        "id": "f1b53ba6"
      },
      "outputs": [],
      "source": [
        "# Code to calcualte Total Sales Revenue and its Components for each group.\n",
        "combined_dataset = dataset['sales'].merge(dataset['products'], on='ProductID', how='left') \\\n",
        "                                .merge(dataset['employees'], left_on='SalesPersonID', right_on='EmployeeID', how='left') \\\n",
        "                                .merge(dataset['categories'], left_on='NewCategoryID', right_on='CategoryID', how='left') \\\n",
        "                                .merge(dataset['cities'], on='CityID', how='left') \\\n",
        "                                .merge(dataset['countries'], on='CountryID', how='left')\n",
        "# Feature engineering, making new features to do univariate analysis with\n",
        "# Binning SalesDate into monthly bins, weekly bins, hourly bins and day of the week bins\n",
        "combined_dataset['SalesMonth'] = combined_dataset['SalesDate'].dt.to_period('M')\n",
        "combined_dataset['SalesWeek'] = combined_dataset['SalesDate'].dt.to_period('W')\n",
        "combined_dataset['SalesDayOfWeek'] = combined_dataset['SalesDate'].dt.day_name()\n",
        "combined_dataset['SalesHourOfDay'] = combined_dataset['SalesDate'].dt.hour\n",
        "\n",
        "component_cols = ['TransactionNumber', 'Price', 'Quantity', 'Discount']\n",
        "group_cols = ['CategoryName', 'CountryName', 'CityName', 'Gender', 'SalesMonth', 'SalesWeek', 'SalesDayOfWeek', 'SalesHourOfDay']\n",
        "combined_dataset['Revenue'] = combined_dataset['Price'] * combined_dataset['Quantity'] * (1 - combined_dataset['Discount'])\n",
        "for col in group_cols:\n",
        "    display(Markdown(f\"Total Sales and its components by {col}\"))\n",
        "    grouped = combined_dataset.groupby(col, observed=False).agg(\n",
        "        TotalSalesRevenue = ('Revenue', 'sum'),\n",
        "        TotalVolume = ('Quantity', 'sum'),\n",
        "        WeightedAvgPrice=('Price', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "        WeightedAvgDiscount=('Discount', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "        Transactions=('TransactionNumber', 'count'),\n",
        "    ).reset_index()\n",
        "    grouped['RevenuePerTransaction'] = grouped['TotalSalesRevenue']/grouped['Transactions']\n",
        "    grouped['VolumePerTransaction'] = grouped['TotalVolume']/grouped['Transactions']\n",
        "    display(Markdown(grouped.to_markdown(index=False)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking to see if there are more products per category which accounts for the discrpancy\n",
        "grouped = combined_dataset.groupby(['CategoryName'], observed=False).agg(\n",
        "        TotalSalesRevenue = ('Revenue', 'sum'),\n",
        "        TotalVolume = ('Quantity', 'sum'),\n",
        "        ProductsPerCategory=('ProductID', 'nunique')\n",
        ").reset_index()\n",
        "grouped['RevenuePerProduct'] = grouped['TotalSalesRevenue']/grouped['ProductsPerCategory']\n",
        "grouped['VolumePerProduct'] = grouped['TotalVolume']/grouped['ProductsPerCategory']\n",
        "display(Markdown(grouped.to_markdown(index=False)))"
      ],
      "metadata": {
        "id": "xH3HXHwelxjQ"
      },
      "id": "xH3HXHwelxjQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking which products sell more\n",
        "\n",
        "grouped = combined_dataset.groupby(['CategoryName', 'ProductName'], observed=True).agg(\n",
        "        TotalSalesRevenue = ('Revenue', 'sum'),\n",
        "        TotalVolume = ('Quantity', 'sum'),\n",
        "        WeightedAvgPrice=('Price', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "        WeightedAvgDiscount=('Discount', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "        Transactions=('TransactionNumber', 'count')\n",
        ").reset_index()\n",
        "grouped['RevenuePerTransaction'] = grouped['TotalSalesRevenue']/grouped['Transactions']\n",
        "grouped['VolumePerTransaction'] = grouped['TotalVolume']/grouped['Transactions']\n",
        "grouped = grouped.sort_values('TotalSalesRevenue', ascending=False)\n",
        "display(Markdown(grouped.head(50).to_markdown(index=False)))\n",
        "display(Markdown(f\"The Coefficient of Variation of TotalVolume is {grouped['TotalVolume'].std()/grouped['TotalVolume'].mean()*100}%\"))"
      ],
      "metadata": {
        "id": "s7BE641SqPLE"
      },
      "id": "s7BE641SqPLE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since for each product the TotalVolume is nearly the same (<1% of Coefficient of variation), that means the main revenue driver for a product is price of the product.\n",
        "\n",
        "4 cities have more Total Sales Revenue and volume than the others:\n",
        "- Lubbock\n",
        "- New Orleans\n",
        "- Columbus\n",
        "- Baltimore\n",
        "\n",
        "Male employees have more Total Sales Revenue and volume than Female Employees\n",
        "\n",
        "This needs to be investigated further."
      ],
      "metadata": {
        "id": "Ki_kozsjUDtH"
      },
      "id": "Ki_kozsjUDtH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets start to see if these 4 cities have more salespeople to generate a higher volume."
      ],
      "metadata": {
        "id": "Boh1BcCJcyZb"
      },
      "id": "Boh1BcCJcyZb"
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = combined_dataset.groupby('CityName', observed=True).agg(\n",
        "    SalesPersonCount = ('SalesPersonID', 'nunique'),\n",
        "    TotalSalesRevenue = ('Revenue', 'sum')).reset_index()\n",
        "grouped['RevenuePerSalesPerson'] = grouped['TotalSalesRevenue'] / grouped['SalesPersonCount']\n",
        "grouped = grouped.sort_values('SalesPersonCount', ascending=False)\n",
        "display(Markdown(grouped.to_markdown(index=False)))\n",
        "display(Markdown(f\"The Coefficient of Variation of RevenuePerSalesPerson is {grouped['RevenuePerSalesPerson'].std()/grouped['RevenuePerSalesPerson'].mean()*100}%\"))"
      ],
      "metadata": {
        "id": "V0lj1MJxc8Kp"
      },
      "id": "V0lj1MJxc8Kp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here we can see that Lubbock, Columbus, New Orleans, Baltimore have more sales persons than the rest of the cities and Revenue per Sales Person is almost constant (Coefficient of variation ~ 0.4%), there it means the more sales people generate more revenue irrespective of their location."
      ],
      "metadata": {
        "id": "k7kBdc-XeHAT"
      },
      "id": "k7kBdc-XeHAT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking to see if there are more male employees than female employees to account for difference in Revenue\n",
        "grouped = combined_dataset.groupby('Gender', observed=True).agg(\n",
        "    SalesPersonCount = ('SalesPersonID', 'nunique'),\n",
        "    TotalSalesRevenue = ('Revenue', 'sum')).reset_index()\n",
        "grouped['RevenuePerSalesPerson'] = grouped['TotalSalesRevenue'] / grouped['SalesPersonCount']\n",
        "grouped = grouped.sort_values('SalesPersonCount', ascending=False)\n",
        "display(Markdown(grouped.to_markdown(index=False)))\n",
        "display(Markdown(f\"The Coefficient of Variation of RevenuePerSalesPerson is {grouped['RevenuePerSalesPerson'].std()/grouped['RevenuePerSalesPerson'].mean()*100}%\"))"
      ],
      "metadata": {
        "id": "Oxrzh9DkmxBp"
      },
      "id": "Oxrzh9DkmxBp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this we can see that Revenue per Sales Person is the almost the same for Male and Female salespeople, and the only reason that there is more Total Sales Revenue for male salespeople is because that there are more male salespeople."
      ],
      "metadata": {
        "id": "NHgqN5Dfo0v3"
      },
      "id": "NHgqN5Dfo0v3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Customer Segmentation\n",
        "\n",
        "snapshot_date = combined_dataset['SalesDate'].max() + pd.Timedelta(days=1) # Takes the date, to be considered for recency\n",
        "grouped = combined_dataset[combined_dataset['SalesDate'].notna()].groupby('CustomerID', observed=False).agg({\n",
        "    'SalesDate': lambda x: (snapshot_date - x.max()).days,\n",
        "    'TransactionNumber': 'count',\n",
        "    'Revenue':  'sum',\n",
        "    'Quantity': 'sum'\n",
        "}).reset_index()\n",
        "grouped.columns=['CustomerID', 'Recency', 'Frequency', 'Monetary', 'Quantity'] # These are the basis the customers are being segmented\n",
        "grouped['AverageTransactionValue'] = grouped['Monetary'] / grouped['Frequency']\n",
        "\n",
        "def jenks_score(series, nb_class=5, reverse=False):\n",
        "    sample = series.sample(n=10000, random_state=1) if len(series) > 5000 else series\n",
        "    breaks = jenkspy.jenks_breaks(sample.values, n_classes=nb_class)\n",
        "    breaks[0] = series.min()\n",
        "    breaks[-1] = series.max()\n",
        "    score = np.digitize(series.values, bins=breaks[1:], right=True) + 1\n",
        "    if reverse:\n",
        "        score = 6 - score\n",
        "    return score\n",
        "\n",
        "grouped['RScore'] = pd.cut(grouped['Recency'], bins=[0,3,7,grouped['Recency'].max()+1], labels=[5,3,1], include_lowest=False).astype(int) # Scores based on last purchase\n",
        "grouped['FScore'] = jenks_score(grouped['Frequency']) # Scores based on number of purchases\n",
        "grouped['MScore'] = jenks_score(grouped['Monetary']) # Scores based on total amount purchased\n",
        "grouped['QScore'] = jenks_score(grouped['Quantity']) # Scores based on total quantity purchased\n",
        "grouped['AScore'] = jenks_score(grouped['AverageTransactionValue']) # Scores based on amount spent on transaction\n",
        "\n",
        "# Assigning a segment based on the derived scores\n",
        "grouped['CustomerSegment'] = 'Regular Shopper'\n",
        "grouped.loc[(grouped['RScore'] == 5) & (grouped['QScore'] == 5), 'CustomerSegment'] = 'Recent Bulk Buyer'\n",
        "grouped.loc[(grouped['FScore'] >= 4) & (grouped['MScore'] >= 3), 'CustomerSegment'] = 'Frequent Product Purchaser'\n",
        "grouped.loc[(grouped['FScore'] >= 4) & (grouped['MScore'] <= 2), 'CustomerSegment'] = 'Frequent Low-Spend Shopper'\n",
        "grouped.loc[(grouped['FScore'] == 1) & ((grouped['MScore'] >= 4) | (grouped['AScore'] >= 4)), 'CustomerSegment'] = 'Infrequent Big Spender'\n",
        "grouped.loc[(grouped['RScore'] <= 2) & (grouped['FScore'] >= 3), 'CustomerSegment'] = 'Slipping Shopper'\n",
        "grouped.loc[(grouped['RScore'] == 1), 'CustomerSegment'] = 'Lost or Inactive Customer'\n",
        "grouped.loc[(grouped['QScore'] == 5) & (grouped['FScore'] <= 2), 'CustomerSegment'] = 'Bulk Shopper (Low Frequency)'\n",
        "grouped.loc[(grouped['RScore'] == 5) & (grouped['MScore'] <= 2) & (grouped['QScore'] <= 2), 'CustomerSegment'] = 'Recent Small Order Shopper'\n",
        "\n",
        "display(Markdown(grouped.head(10).to_markdown(index=False)))"
      ],
      "metadata": {
        "id": "DmbBiWXUG1kR"
      },
      "id": "DmbBiWXUG1kR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the Customer Segmentation to the combined_dataset\n",
        "\n",
        "combined_dataset = pd.merge(left=combined_dataset,\n",
        "                            right=grouped[['CustomerID', 'CustomerSegment']],\n",
        "                            on='CustomerID',\n",
        "                            how='left')\n",
        "# Calculate aggregate metrics based on customer segmentation\n",
        "\n",
        "grouped = combined_dataset.groupby('CustomerSegment', observed=True).agg(\n",
        "    TotalSalesRevenue = ('Revenue', 'sum'),\n",
        "    TotalVolume = ('Quantity', 'sum'),\n",
        "    WeightedAvgPrice=('Price', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "    WeightedAvgDiscount=('Discount', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "    Transactions=('TransactionNumber', 'count'),\n",
        "    Customers = ('CustomerID', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "display(Markdown(grouped.to_markdown(index=False)))"
      ],
      "metadata": {
        "id": "8lOCap2HdK_s"
      },
      "id": "8lOCap2HdK_s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spending habits of the High revenue customer segments\n",
        "grouped = combined_dataset[combined_dataset['CustomerSegment'].isin(['Frequent Product Purchaser', 'Regular Shopper'])].groupby(['CategoryName', 'ProductName'], observed=True).agg(\n",
        "        TotalSalesRevenue = ('Revenue', 'sum'),\n",
        "        TotalVolume = ('Quantity', 'sum'),\n",
        "        WeightedAvgPrice=('Price', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "        WeightedAvgDiscount=('Discount', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "        Transactions=('TransactionNumber', 'count')\n",
        ").reset_index()\n",
        "grouped['RevenuePerTransaction'] = grouped['TotalSalesRevenue']/grouped['Transactions']\n",
        "grouped['VolumePerTransaction'] = grouped['TotalVolume']/grouped['Transactions']\n",
        "grouped = grouped.sort_values('TotalSalesRevenue', ascending=False)\n",
        "display(Markdown(grouped.head(50).to_markdown(index=False)))\n",
        "display(Markdown(f\"The Coefficient of Variation of TotalVolume is {grouped['TotalVolume'].std()/grouped['TotalVolume'].mean()*100}%\"))"
      ],
      "metadata": {
        "id": "vD9y8CsWf_f2"
      },
      "id": "vD9y8CsWf_f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis on FreshMart Data"
      ],
      "metadata": {
        "id": "CMIv3mXVUK9I"
      },
      "id": "CMIv3mXVUK9I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "After analyzing the FreshMart dataset, I performed several manipulations and deep-dived into specific patterns related to total sales revenue. The goal was to identify factors contributing to total sales revenue and find ways to maximise it. Below is a detailed summary of the steps taken, insights derived, and potential reasons for observed patterns.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### Data Manipulations Performed\n",
        "1. **Dataset Exploration**\n",
        "  - Checked for duplicates and missing values.\n",
        "  - Removed features that do not match the column definitions or do not make sense.\n",
        "  - Remapped each product with a category to make logical sense.\n",
        "  - Analysed key metrics like `Quantity`, `Price` and `Discount`.\n",
        "\n",
        "2. **Aggregated Metrics**\n",
        "  - Grouped data by `ProductName`, `SalesPersonID`, `City`, `CategoryName`, `Gender` to find total sales revenue, total volume, avgerage price and average discount for each group.\n",
        "  - Calculated `TotalSalesRevenue`, `TotalVolume`, `WeightedAvgPrice`, `WeightedAvgDiscount`, `RevenuePerTransaction`, `VolumePerTransaction`, `RevenuePerProduct`, `VolumePerProduct`, `RevenuePerSalesPerson`.\n",
        "3. **Feature Engineering**\n",
        "  - Created new metrics:\n",
        "    - `Revenue`: Revenue earned per transaction.\n",
        "    - `SalesMonth`: The month of the transaction.\n",
        "    - `SalesWeek` : The week of the transaction.\n",
        "    - `SalesDayOfWeek`: The day of the week of the transaction.\n",
        "    - `SalesHour`: The hour of the day of the transaction.\n",
        "    - `CustomerSegment`: Customer type based on shopping behaviour.\n",
        "\n",
        "---\n",
        "\n",
        "#### Key Insights & Patterns\n",
        "\n",
        "1. **Revenue and Volume is Stable over Time**\n",
        "  - Total Sales Revenue and Total Volume are consistent over time, this was checked by calculating the Total Sales Revenue and Total Volume monthly, weekly, day of the week wise and hour of the day wise.\n",
        "\n",
        "2. **Product price is the key Revenue driver**\n",
        "  - Total Volume per product is constant and the average discount offered was also constant. The differentiater in revenue was price. The more expensive the product is, the more revenue it generated.\n",
        "\n",
        "3. **Sales Revenue is Directly Proportional to Sales People**\n",
        " - Revenue per sales person is constant, so if there are more sales people, there will be more revenue as long as customer demand supports it.\n",
        "\n",
        "4. **Regular Shoppers and Frequent Product Purchasers are FreshMart's key Revenue Sources**\n",
        "  - Revenue from these segements are more than USD $1,000,000,000$.\n",
        "\n",
        "---\n",
        "#### Hypothesis\n",
        "\n",
        "1. Increasing the prices of products by 10% will increase the revenue by 10% as Total volume per product is constant.\n",
        "\n",
        "2. Adding extra sales people to the stores will proportionally increase the revenue."
      ],
      "metadata": {
        "id": "_8y8xiNdUPHM"
      },
      "id": "_8y8xiNdUPHM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables"
      ],
      "metadata": {
        "id": "-HgYg-FsnvW5"
      },
      "id": "-HgYg-FsnvW5"
    },
    {
      "cell_type": "code",
      "source": [
        "VISUALS_DIRECTORY = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Visuals\")) # Folder where all the visualisations will be saved\n",
        "os.makedirs(VISUALS_DIRECTORY, exist_ok=True)"
      ],
      "metadata": {
        "id": "XU-0jENS7gKj"
      },
      "id": "XU-0jENS7gKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Daily Revenue and Volume Trends"
      ],
      "metadata": {
        "id": "SNuIJPlq0y8I"
      },
      "id": "SNuIJPlq0y8I"
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset['SalesDay'] = combined_dataset['SalesDate'].dt.to_period('D').dt.to_timestamp()\n",
        "\n",
        "grouped = combined_dataset.groupby('SalesDay', observed=True).agg({\n",
        "    'Revenue' : 'sum',\n",
        "    \"Quantity\" : 'sum'\n",
        "}).reset_index()\n",
        "grouped.columns = ['SalesDay', 'TotalSalesRevenue', 'TotalVolume']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "sns.lineplot(data=grouped, x='SalesDay',y='TotalSalesRevenue', label='Revenue', ax=ax)\n",
        "sns.lineplot(data=grouped, x='SalesDay',y='TotalVolume', label='Volume', ax=ax)\n",
        "plt.title('Daily Revenue and Volume Trends')\n",
        "plt.ylabel('Amount')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plot_path = os.path.join(VISUALS_DIRECTORY, \"daily_volume_trend.png\")\n",
        "plt.savefig(plot_path, dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8A0R8zay07x1"
      },
      "id": "8A0R8zay07x1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights from the Chart"
      ],
      "metadata": {
        "id": "fj5j1leP3yi5"
      },
      "id": "fj5j1leP3yi5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that Total Sales Revenue and Total Volume stay stable over time."
      ],
      "metadata": {
        "id": "Q0e0_lFY36An"
      },
      "id": "Q0e0_lFY36An"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights and Business Impact"
      ],
      "metadata": {
        "id": "_kv8Jd6Y4iqt"
      },
      "id": "_kv8Jd6Y4iqt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Consistent Customer Demand\n",
        "  - FreshMart likely has a steady base of regular buyers.\n",
        "  - No reliance on short-term promotions or events to drive volume.\n",
        "\n",
        "2. Limited Seasonality or Campaign Impact\n",
        "  - No strong weekly/monthly spikes means promotions, holidays, or external events may not significantly affect customer buying behavior — at least in terms of volume."
      ],
      "metadata": {
        "id": "k7L4N7wG4nJk"
      },
      "id": "k7L4N7wG4nJk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Product Price vs Revenue (Higher Price -> Higher Revenue)"
      ],
      "metadata": {
        "id": "IkfrTzvo7_em"
      },
      "id": "IkfrTzvo7_em"
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = combined_dataset.groupby(['CategoryName', 'ProductName'], observed=True).agg(\n",
        "        TotalSalesRevenue = ('Revenue', 'sum'),\n",
        "        TotalVolume = ('Quantity', 'sum'),\n",
        "        WeightedAvgPrice=('Price', lambda x: (x * combined_dataset.loc[x.index, 'Quantity']).sum() / combined_dataset.loc[x.index, 'Quantity'].sum()),\n",
        "\n",
        ").reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    data=grouped,\n",
        "    x='WeightedAvgPrice',\n",
        "    y='TotalSalesRevenue',\n",
        "    size='TotalVolume',\n",
        "    sizes=(20, 200),\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "plt.title('Product Price vs Revenue\\n(Higher Price → Higher Revenue)')\n",
        "plt.xlabel('Average Product Price')\n",
        "plt.ylabel('Total Revenue')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plot_path = os.path.join(VISUALS_DIRECTORY, \"product_price_vs_revenue.png\")\n",
        "plt.savefig(plot_path, dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GsqXHR5q8gtU"
      },
      "id": "GsqXHR5q8gtU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights from the Chart"
      ],
      "metadata": {
        "id": "DvpfekKF9RcP"
      },
      "id": "DvpfekKF9RcP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Product price is the key Revenue driver**\n",
        "Volume and discount are constant → so variation in revenue is driven by price."
      ],
      "metadata": {
        "id": "J2OYL3Pf9XyL"
      },
      "id": "J2OYL3Pf9XyL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights and Business Impact"
      ],
      "metadata": {
        "id": "38fF9I6s9iPu"
      },
      "id": "38fF9I6s9iPu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Revenue Growth Relies on Product Mix, Not Quantity\n",
        "  - Since volume is stable, revenue growth depends on shifting sales toward higher-priced products.\n",
        "  - Introducing premium products or upselling existing ones can significantly boost revenue.\n",
        "  - Low-margin or low-priced products contribute less to overall growth and may need repositioning.\n",
        "2. Discounting Has Limited Influence\n",
        "  - With average discounts constant and not driving revenue variation, discounting does not appear to be a key lever.\n",
        "  - Customers are not highly price-sensitive at current discount levels.\n",
        "  - Avoiding unnecessary discounts can protect margins.\n",
        "3. Focus Marketing on High-Value Products\n",
        "  - High-priced products are the primary revenue drivers.\n",
        "  - Marketing campaigns should prioritize visibility and promotion of these products.\n",
        "  - Optimising product recommendations and search placements toward high-revenue items can increase return on ad spend.\n",
        "\n"
      ],
      "metadata": {
        "id": "qEOMM6PA-HMZ"
      },
      "id": "qEOMM6PA-HMZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sales People vs Sales Revenue"
      ],
      "metadata": {
        "id": "acKwvHGdBLwW"
      },
      "id": "acKwvHGdBLwW"
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = combined_dataset.groupby('CityName', observed=True).agg(\n",
        "    SalesPersonCount = ('SalesPersonID', 'nunique'),\n",
        "    TotalSalesRevenue = ('Revenue', 'sum')).reset_index()\n",
        "grouped['RevenuePerSalesPerson'] = grouped['TotalSalesRevenue'] / grouped['SalesPersonCount']\n",
        "\n",
        "# Scatter plot with regression line\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.regplot(\n",
        "    data=grouped,\n",
        "    x='SalesPersonCount',\n",
        "    y='TotalSalesRevenue',\n",
        "    ci=None,  # no confidence interval\n",
        "    line_kws={\"color\": \"red\"},\n",
        "    scatter_kws={\"s\": 60}\n",
        ")\n",
        "\n",
        "plt.title('Total Sales Revenue vs Number of Salespeople per City')\n",
        "plt.xlabel('Number of Salespeople (per City)')\n",
        "plt.ylabel('Total Sales Revenue')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plot_path = os.path.join(VISUALS_DIRECTORY, \"salespeople_vs_revenue.png\")\n",
        "plt.savefig(plot_path, dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gdVSbMfjBPtv"
      },
      "id": "gdVSbMfjBPtv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights from Chart"
      ],
      "metadata": {
        "id": "firCA_rND_5q"
      },
      "id": "firCA_rND_5q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that total sales revenue for a city is directly proportional to the number of sales people a city has."
      ],
      "metadata": {
        "id": "xqNPI1XBEFh1"
      },
      "id": "xqNPI1XBEFh1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights and Business Impact"
      ],
      "metadata": {
        "id": "sSczWd1yEUqK"
      },
      "id": "sSczWd1yEUqK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Scalable Revenue Growth Strategy\n",
        "  - If each additional salesperson contributes a consistent amount to total revenue, then increasing the sales team size presents a predictable and scalable path to revenue growth.\n",
        "  - This linear relationship enables revenue forecasting based purely on headcount.\n",
        "2. Workforce Planning and Budget Justification\n",
        "  - Stable revenue per salesperson provides a clear basis for financial planning.\n",
        "  - FreshMart can confidently justify the costs of hiring additional salespeople, as their expected contribution to revenue is quantifiable and reliable.\n",
        "3. Territory Optimization\n",
        "  - The current distribution of salespeople is uneven, with most cities having only one salesperson.\n",
        "  - This suggests that some territories may be underutilized.\n",
        "  - By reallocating or increasing staff in cities with potential, FreshMart can optimize coverage and performance."
      ],
      "metadata": {
        "id": "haOVkojKEZqv"
      },
      "id": "haOVkojKEZqv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customer Segmentation by Revenue and Customer Count"
      ],
      "metadata": {
        "id": "50WpoCX-F3jQ"
      },
      "id": "50WpoCX-F3jQ"
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = combined_dataset.groupby('CustomerSegment', observed=True).agg(\n",
        "    TotalSalesRevenue = ('Revenue', 'sum'),\n",
        "    TotalVolume = ('Quantity', 'sum'),\n",
        "    Customers = ('CustomerID', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create scatter plot\n",
        "scatter = plt.scatter(\n",
        "    data=grouped,\n",
        "    x='Customers',\n",
        "    y='TotalSalesRevenue',\n",
        "    s=grouped['TotalVolume'] / 10000,\n",
        "    c=range(len(grouped)),\n",
        "    cmap='viridis',\n",
        "    alpha=0.8,\n",
        "    edgecolors='k'\n",
        ")\n",
        "\n",
        "texts = []\n",
        "for i, row in grouped.iterrows():\n",
        "    texts.append(plt.text(row['Customers'], row['TotalSalesRevenue'], row['CustomerSegment'], fontsize=9, ha='center', va='bottom'))\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray', lw=0.5))\n",
        "\n",
        "plt.title('Customer Segments by Revenue and Customer Count')\n",
        "plt.xlabel('Number of Customers')\n",
        "plt.ylabel('Total Sales Revenue')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plot_path = os.path.join(VISUALS_DIRECTORY, \"customer_segments_by_revenue_and_customer_count.png\")\n",
        "plt.savefig(plot_path, dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TD4drTsIGFO7"
      },
      "id": "TD4drTsIGFO7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights from Chart"
      ],
      "metadata": {
        "id": "-kbCDh9dIG0e"
      },
      "id": "-kbCDh9dIG0e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Regular Shoppers are the Primary Revenue Drivers\n",
        "  - Total Sales Revenue: USD 1.55B\n",
        "  - Customer Count: 32,033\n",
        "  - This segment is the largest in terms of both revenue and customer base, indicating that consistent, habitual buyers are the foundation of the business's revenue stream.\n",
        "2. Frequent Product Purchasers Also Generate Significant Revenue\n",
        "  - Total Sales Revenue: USD 1.31B\n",
        "  - Customer Count: 19,267\n",
        "  - Although smaller in number than Regular Shoppers, this group generates a comparable amount of revenue, highlighting their high purchasing intensity or frequency.\n",
        "3. Recent Small Order Shoppers Present Growth Potential\n",
        "  - Total Sales Revenue: USD 630.9M\n",
        "  - Customer Count: 32,829 (the largest segment)\n",
        "  - Despite contributing significantly to revenue, the lower average transaction value suggests an opportunity to upsell or bundle products to increase value per transaction.\n",
        "4. Infrequent Big Spenders and Recent Bulk Buyers are High-Value Niche Segments\n",
        "  - Infrequent Big Spenders TSR: USD 265.9M\n",
        "  - Recent Bulk Buyer TSR: USD 271.8M\n",
        "  - These groups, while smaller in customer count, contribute substantial revenue. They may be good candidates for targeted high-value campaigns or loyalty programs.\n",
        "5. Bulk Shoppers (Low Frequency) and Lost/Inactive Customers Contribute Lower Revenue\n",
        " -  Bulk Shoppers TSR: USD 137.0M\n",
        " -  Lost/Inactive TSR: USD 101.5M\n",
        " -  These segments have low revenue and may either need re-engagement strategies or can be deprioritized depending on customer lifetime value.\n",
        "\n",
        "6. Frequent Low-Spend Shoppers Have Limited Revenue Contribution\n",
        "  - TSR: USD 55.4M\n",
        "  - Customer Count: 2,310\n",
        "  - This group has limited impact on total revenue and may incur higher service costs relative to revenue contribution.\n",
        "\n"
      ],
      "metadata": {
        "id": "P4mdTg3ZIKcG"
      },
      "id": "P4mdTg3ZIKcG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights and Business Impact"
      ],
      "metadata": {
        "id": "gP8V0Q7JJG3b"
      },
      "id": "gP8V0Q7JJG3b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prioritize Regular and Frequent Product Purchasers\n",
        "  - These segments are responsible for the majority of total sales revenue.\n",
        "  - Retention and personalized engagement strategies targeting these groups will directly support revenue sustainability.\n",
        "\n",
        "2. Optimize Engagement for Recent Small Order Shoppers\n",
        "  - With the largest customer base but a lower revenue per customer, this segment represents a clear upsell and cross-sell opportunity.\n",
        "  - Bundling, promotions, or loyalty incentives could improve average revenue per user.\n",
        "\n",
        "3. Target Niche High-Value Segments Strategically\n",
        "  - Infrequent Big Spenders and Recent Bulk Buyers offer strong revenue despite smaller sizes.\n",
        "  - Consider tailored campaigns to improve frequency and strengthen brand loyalty.\n",
        "\n",
        "4. Re-engagement or Reallocation for Low-Impact Segments\n",
        "  - Lost/Inactive and Frequent Low-Spend Shoppers contribute the least to TSR.\n",
        "  - Re-engagement campaigns should be low-cost and data-driven; otherwise, marketing resources may be better spent elsewhere.\n",
        "\n",
        "5. Use TSR and Customer Count to Inform Segment-Level Investment\n",
        "  - Investment in customer experience, marketing, or sales resources should be weighted toward segments with high revenue potential.\n",
        "  - This allows for more efficient allocation of budget and higher ROI across segments."
      ],
      "metadata": {
        "id": "RDQuvpncJLA8"
      },
      "id": "RDQuvpncJLA8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Daily Revenue Contribution by Category"
      ],
      "metadata": {
        "id": "1WxiGwYWKeJ9"
      },
      "id": "1WxiGwYWKeJ9"
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = combined_dataset.groupby(['SalesDay', 'CategoryName'])['Revenue'].sum().unstack(fill_value=0)\n",
        "grouped = grouped[grouped.sum().sort_values(ascending=False).index]\n",
        "\n",
        "grouped.plot(kind='area', stacked=True, figsize=(14,7), colormap='tab20')\n",
        "plt.title('Daily Revenue Contribution by Product Category')\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Revenue')\n",
        "plt.legend(title='Product Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plot_path = os.path.join(VISUALS_DIRECTORY, \"daily_revenue_by_category.png\")\n",
        "plt.savefig(plot_path, dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b5O8MI8hKiW4"
      },
      "id": "b5O8MI8hKiW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights from Chart"
      ],
      "metadata": {
        "id": "1Y7e-jzWLkyb"
      },
      "id": "1Y7e-jzWLkyb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Daily Revenue per Category is Consistent\n",
        "  - Despite the differences in volume, classification, or features, each product category contributes a stable and predictable amount of revenue each day.\n",
        "  - There are no major fluctuations or seasonal patterns within individual categories on a daily basis.\n",
        "2. Category Performance is Operationally Stable\n",
        "  - This trend suggests that most product categories are not heavily impacted by day-to-day demand shifts, promotions, or irregular events.\n",
        "  - Their performance appears to be decoupled from external volatility at the daily level."
      ],
      "metadata": {
        "id": "fS7y-LB-L6P4"
      },
      "id": "fS7y-LB-L6P4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights and Business Impact"
      ],
      "metadata": {
        "id": "Eo7XVST9MC-K"
      },
      "id": "Eo7XVST9MC-K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Enables Accurate Daily Forecasting\n",
        "  - With consistent daily TSR per category, forecasting becomes highly accurate. The business can confidently plan revenue projections at the daily or weekly level, leading to tighter control over targets, cash flow, and demand planning.\n",
        "\n",
        "2. Streamlines Inventory and Fulfillment Planning\n",
        "  - Operational teams can rely on stable daily revenue figures to plan inventory replenishment, staffing, and logistics more effectively, reducing stockouts or overstocking risks.\n",
        "\n",
        "3. Simplifies Marketing Strategy\n",
        "  - If revenue is stable without promotional influence, it may indicate low responsiveness to campaigns or organic purchasing behavior. Marketing teams can refocus efforts on boosting underperforming categories, rather than maintaining already stable ones."
      ],
      "metadata": {
        "id": "YiwzXeI1MGI_"
      },
      "id": "YiwzXeI1MGI_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### City Wise Revenue"
      ],
      "metadata": {
        "id": "DgCbG-xFOS2z"
      },
      "id": "DgCbG-xFOS2z"
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = combined_dataset.groupby('CityName', observed=True).agg(\n",
        "    TotalSalesRevenue=('Revenue', 'sum'),\n",
        "    SalesPersonCount=('SalesPersonID', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"city_geocoder\")\n",
        "\n",
        "# Function to geocode city with retry and delay\n",
        "def get_lat_lon(city):\n",
        "    try:\n",
        "        location = geolocator.geocode(city)\n",
        "        if location:\n",
        "            return location.latitude, location.longitude\n",
        "        else:\n",
        "            return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error geocoding {city}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "latitudes = []\n",
        "longitudes = []\n",
        "for city in grouped['CityName']:\n",
        "    lat, lon = get_lat_lon(city)\n",
        "    latitudes.append(lat)\n",
        "    longitudes.append(lon)\n",
        "    time.sleep(1)  # pause for Nominatim usage policy\n",
        "\n",
        "grouped['Latitude'] = latitudes\n",
        "grouped['Longitude'] = longitudes\n",
        "grouped = grouped.dropna(subset=['Latitude', 'Longitude'])\n",
        "\n",
        "grouped[\"Size\"] = grouped[\"Revenue\"] / 5e6  # adjust scale as needed\n",
        "\n",
        "# Create map\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattermapbox(\n",
        "    lat=grouped[\"Latitude\"],\n",
        "    lon=grouped[\"Longitude\"],\n",
        "    mode=\"markers+text\",\n",
        "    marker=go.scattermapbox.Marker(\n",
        "        size=grouped[\"Size\"],\n",
        "        color=\"royalblue\",\n",
        "        opacity=0.6\n",
        "    ),\n",
        "    text=grouped[\"SalesPersonCount\"],\n",
        "    textposition=\"middle center\",\n",
        "    hovertemplate=(\n",
        "        \"<b>%{text} Salespeople</b><br>\"\n",
        "        \"Revenue: $%{marker.size:.0f} (scaled)<br>\"\n",
        "        \"Lat: %{lat}<br>Lon: %{lon}<extra></extra>\"\n",
        "    ),\n",
        "    name=\"City\"\n",
        "))\n",
        "fig.update_layout(\n",
        "    mapbox_style=\"carto-positron\",\n",
        "    mapbox_zoom=1.2,\n",
        "    mapbox_center={\"lat\": 15, \"lon\": 0},\n",
        "    title=\"Interactive Map: City Sales Revenue and Salesperson Count\",\n",
        "    margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0}\n",
        ")\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Egqi0TYROoTg"
      },
      "id": "Egqi0TYROoTg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}